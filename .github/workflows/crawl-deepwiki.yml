name: Crawl DeepWiki Documentation

on:
  # Trigger on push to main branch
  push:
    branches: [ main ]
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      repo_identifier:
        description: 'Repository identifier (owner/repo or GitHub URL)'
        required: false
        default: ''
        type: string

  # Trigger on schedule (daily at 2 AM UTC)
  schedule:
    - cron: '0 2 * * *'

permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "deepwiki-crawl"
  cancel-in-progress: false

jobs:
  crawl-and-deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    outputs:
      repo_exists: ${{ steps.check-repo.outputs.repo_exists }}
      org_repo: ${{ steps.check-repo.outputs.org_repo }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: |
        npm install node-fetch cheerio @types/node

    - name: Check if repository exists on DeepWiki
      id: check-repo
      run: |
        cat > check-deepwiki.js << 'EOF'
        const fetch = require('node-fetch').default;

        async function checkRepoExistsOnDeepWiki(repoIdentifier) {
          // Extract org/repo from different input formats
          let orgRepo = '';
          
          if (repoIdentifier.startsWith('https://github.com/')) {
            const url = new URL(repoIdentifier);
            const pathParts = url.pathname.split('/').filter(Boolean);
            if (pathParts.length >= 2) {
              orgRepo = `${pathParts[0]}/${pathParts[1]}`;
            }
          } else if (repoIdentifier.startsWith('https://deepwiki.com/')) {
            const url = new URL(repoIdentifier);
            const pathParts = url.pathname.split('/').filter(Boolean);
            if (pathParts.length >= 2) {
              orgRepo = `${pathParts[0]}/${pathParts[1]}`;
            }
          } else if (repoIdentifier.includes('/')) {
            const parts = repoIdentifier.split('/');
            if (parts.length === 2 && parts[0] && parts[1]) {
              orgRepo = repoIdentifier;
            }
          }

          if (!orgRepo) {
            console.error('Invalid repository identifier format');
            process.exit(1);
          }

          console.log(`Checking if ${orgRepo} exists on DeepWiki...`);

          try {
            const searchUrl = `https://api.devin.ai/ada/list_public_indexes?search_repo=${encodeURIComponent(orgRepo)}`;
            const response = await fetch(searchUrl, {
              headers: {
                accept: "*/*",
                "accept-language": "en,en-US;q=0.9",
              },
              method: "GET",
            });

            if (!response.ok) {
              console.error(`API error: ${response.status} ${response.statusText}`);
              process.exit(1);
            }

            const responseBodyText = await response.text();
            const parsedJson = JSON.parse(responseBodyText);
            
            if (parsedJson && Array.isArray(parsedJson.indices)) {
              const apiResults = parsedJson.indices;
              const repoExists = apiResults.some(repo => repo.repo_name === orgRepo);
              
              if (repoExists) {
                console.log(`✅ Repository ${orgRepo} found on DeepWiki`);
                const fs = require('fs');
                fs.appendFileSync(process.env.GITHUB_OUTPUT, `repo_exists=true\n`);
                fs.appendFileSync(process.env.GITHUB_OUTPUT, `org_repo=${orgRepo}\n`);
              } else {
                console.log(`❌ Repository ${orgRepo} not found on DeepWiki`);
                console.log(`Will attempt to crawl and create documentation...`);
                const fs = require('fs');
                fs.appendFileSync(process.env.GITHUB_OUTPUT, `repo_exists=false\n`);
                fs.appendFileSync(process.env.GITHUB_OUTPUT, `org_repo=${orgRepo}\n`);
              }
            } else {
              console.error('Invalid API response format');
              process.exit(1);
            }
          } catch (error) {
            console.error('Error checking repository existence:', error.message);
            process.exit(1);
          }
        }

        const repoIdentifier = process.argv[2];
        checkRepoExistsOnDeepWiki(repoIdentifier);
        EOF
        
        node check-deepwiki.js "${{ steps.repo-info.outputs.repo_id }}"

    - name: Determine repository identifier
      id: repo-info
      run: |
        if [ -n "${{ github.event.inputs.repo_identifier }}" ]; then
          echo "repo_id=${{ github.event.inputs.repo_identifier }}" >> $GITHUB_OUTPUT
        else
          echo "repo_id=${{ github.repository }}" >> $GITHUB_OUTPUT
        fi
        echo "Repository identifier: $(cat $GITHUB_OUTPUT | grep repo_id | cut -d'=' -f2)"

    - name: Create crawl script
      run: |
        cat > crawl-deepwiki.js << 'EOF'
        const fetch = require('node-fetch').default;
        const cheerio = require('cheerio');
        const fs = require('fs');
        const { URL } = require('url');

        const MAX_CONCURRENCY = 5;

        function isValidHttpUrl(string) {
          let url;
          try {
            url = new URL(string);
          } catch (_) {
            return false;
          }
          return url.protocol === "http:" || url.protocol === "https:";
        }

        function getBaseUrl(repoIdentifier) {
          if (isValidHttpUrl(repoIdentifier)) {
            const url = new URL(repoIdentifier);
            if (url.hostname === "github.com" || url.hostname === "www.github.com") {
              const pathParts = url.pathname.split("/").filter(Boolean);
              if (pathParts.length >= 2) {
                return `https://deepwiki.com/${pathParts[0]}/${pathParts[1]}/`;
              }
            } else if (url.hostname === "deepwiki.com" || url.hostname === "www.deepwiki.com") {
              const pathParts = url.pathname.split("/").filter(Boolean);
              if (pathParts.length >= 2) {
                return `https://deepwiki.com/${pathParts[0]}/${pathParts[1]}/`;
              }
            }
          } else {
            const parts = repoIdentifier.split("/");
            if (parts.length === 2 && parts[0] && parts[1]) {
              return `https://deepwiki.com/${parts[0]}/${parts[1]}/`;
            }
          }
          return null;
        }

        async function crawlPage(url, baseUrl, visited, queue, allContent, stats) {
          if (!url.startsWith(baseUrl)) {
            return;
          }

          console.log(`Crawling: ${url}`);

          let response = null;
          try {
            response = await fetch(url);

            if (!response.ok) {
              stats.failed++;
              console.log(`Failed to fetch ${url}: ${response.status}`);
              return;
            }

            stats.successful++;
            const html = await response.text();
            const $ = cheerio.load(html);

            const contentSelector = "div.prose-custom";
            const pageContent = $(contentSelector).text().trim();
            if (pageContent) {
              allContent.push(`## Page: ${url}\n\n${pageContent}\n\n---\n\n`);
            }

            $("a[href]").each((_, element) => {
              const link = $(element).attr("href");
              if (link) {
                try {
                  const absoluteUrl = new URL(link, url).toString();
                  const absoluteUrlWithoutHash = absoluteUrl.split("#")[0];

                  if (absoluteUrl.startsWith(baseUrl) && !visited.has(absoluteUrlWithoutHash)) {
                    queue.push(absoluteUrl);
                  }
                } catch (e) {
                  // Skip invalid URLs
                }
              }
            });
          } catch (error) {
            stats.failed++;
            console.log(`Error crawling ${url}:`, error.message);
          }
        }

        async function crawlWorker(queue, visited, baseUrl, allContent, stats, activeCount) {
          if (activeCount.current >= MAX_CONCURRENCY) {
            return;
          }
          activeCount.current++;
          
          try {
            let keepWorking = true;
            while (keepWorking) {
              const url = queue.shift();
              if (!url) {
                keepWorking = false;
                break;
              }

              const urlWithoutHash = url.split("#")[0];
              if (visited.has(urlWithoutHash)) {
                continue;
              }
              visited.add(urlWithoutHash);

              stats.attempted++;
              await crawlPage(url, baseUrl, visited, queue, allContent, stats);

              // Spawn additional workers if needed
              while (queue.length > 0 && activeCount.current < MAX_CONCURRENCY) {
                setImmediate(() => crawlWorker(queue, visited, baseUrl, allContent, stats, activeCount));
              }
            }
          } finally {
            activeCount.current--;
          }
        }

        async function main() {
          const repoIdentifier = process.argv[2];
          const baseUrl = getBaseUrl(repoIdentifier);

          if (!baseUrl) {
            console.error("Invalid repository identifier. Use format 'org/repo' or GitHub URL.");
            process.exit(1);
          }

          console.log(`Starting crawl for ${repoIdentifier} at ${baseUrl}`);

          const visited = new Set();
          const queue = [];
          const allContent = [];
          const activeCount = { current: 0 };
          
          const crawlStats = {
            attempted: 0,
            successful: 0,
            failed: 0,
          };

          // Seed the queue
          queue.push(baseUrl);

          // Start initial worker
          const workers = [];
          workers.push(crawlWorker(queue, visited, baseUrl, allContent, crawlStats, activeCount));

          // Wait for completion
          while (queue.length > 0 || activeCount.current > 0) {
            await new Promise(resolve => setTimeout(resolve, 100));
          }

          console.log(`Crawl complete. Attempted: ${crawlStats.attempted}, Successful: ${crawlStats.successful}, Failed: ${crawlStats.failed}`);

          if (allContent.length > 0) {
            const finalContent = allContent.join('\n');
            
            // Create index.html with the content
            const htmlContent = `<!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>DeepWiki Documentation - ${repoIdentifier}</title>
            <style>
                body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; }
                h2 { color: #0366d6; border-bottom: 1px solid #e1e4e8; padding-bottom: 10px; }
                hr { border: none; border-top: 1px solid #e1e4e8; margin: 2em 0; }
                pre { background: #f6f8fa; padding: 1em; border-radius: 6px; overflow-x: auto; }
                code { background: #f6f8fa; padding: 0.2em 0.4em; border-radius: 3px; }
                .header { text-align: center; margin-bottom: 2em; }
                .redirect-notice { background: #fff3cd; border: 1px solid #ffeaa7; border-radius: 6px; padding: 1em; margin-bottom: 2em; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>DeepWiki Documentation</h1>
                <p>Repository: <code>${repoIdentifier}</code></p>
                <div class="redirect-notice">
                    <strong>📍 This documentation is also available at:</strong><br>
                    <a href="https://deepwiki.com/${repoIdentifier.replace('https://github.com/', '').replace('https://deepwiki.com/', '')}" target="_blank">
                        https://deepwiki.com/${repoIdentifier.replace('https://github.com/', '').replace('https://deepwiki.com/', '')}
                    </a>
                </div>
            </div>
            <div id="content">
        ${finalContent.split('\n').map(line => {
          if (line.startsWith('## Page:')) {
            return `<h2>${line.substring(3)}</h2>`;
          } else if (line === '---') {
            return '<hr>';
          } else if (line.trim()) {
            return `<p>${line}</p>`;
          }
          return '';
        }).join('\n')}
            </div>
        </body>
        </html>`;

            fs.writeFileSync('index.html', htmlContent);
            fs.writeFileSync('deepwiki-content.md', finalContent);
            
            console.log('Generated index.html and deepwiki-content.md');
          } else {
            console.error('No content extracted. Check repository URL or Deepwiki availability.');
            process.exit(1);
          }
        }

        main().catch(console.error);
        EOF

    - name: Run DeepWiki crawler
      run: |
        node crawl-deepwiki.js "${{ steps.repo-info.outputs.repo_id }}"

    - name: Setup Pages
      uses: actions/configure-pages@v4

    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: '.'

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4

    - name: Show results summary
      run: |
        if [ "${{ steps.check-repo.outputs.repo_exists }}" == "true" ]; then
          echo "✅ Repository ${{ steps.check-repo.outputs.org_repo }} was already indexed on DeepWiki!"
          echo "🔗 Original DeepWiki: https://deepwiki.com/${{ steps.check-repo.outputs.org_repo }}"
          echo "🔗 GitHub Pages mirror: ${{ steps.deployment.outputs.page_url }}"
        else
          if [ -f "deepwiki-content.md" ]; then
            echo "✅ DeepWiki content successfully crawled and deployed!"
            echo "📄 Created documentation for ${{ steps.check-repo.outputs.org_repo }}"
            echo "🔗 Available at: ${{ steps.deployment.outputs.page_url }}"
            echo "💡 This repository was not previously indexed on DeepWiki"
          else
            echo "❌ No content was crawled for ${{ steps.check-repo.outputs.org_repo }}"
            echo "💡 Repository may not have accessible documentation pages"
          fi
        fi